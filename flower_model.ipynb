{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9fe6267-6b3e-43f7-adfd-42874fcc10b1",
   "metadata": {},
   "source": [
    "# IT3103 - Assignment 1 - Advanced Topics in AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69de7622-adc1-4074-949e-83104de55d09",
   "metadata": {},
   "source": [
    "## ðŸŒ¼ Flower Classifier ðŸŒ¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946d0e3-85a7-412c-a8c0-08c32c4cc452",
   "metadata": {},
   "source": [
    "### Team Members:\n",
    "- Tan Qian Peng (234504H)\n",
    "- Rethika\n",
    "- Harith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec0088b-f3b7-4056-bbf2-d90ca2749637",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4017ebeb-f5a8-4e68-85d8-dc75721f1d23",
   "metadata": {},
   "source": [
    "This is a model that classifies flowers by different kinds (i.e. daisy, dandelion, roses, sunflowers, and tulips). In this notebook, we will be presenting our own neural network and how we will program our machine to understand and classify flowers into their own respective types.\n",
    "\n",
    "The priority of our model would be to ensure that we have more than 70% accuracy, while avoiding as much overlapping as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db134e25-db29-4eb9-a754-3d3c3cb26698",
   "metadata": {},
   "source": [
    "### Section 1: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd5cb09-ce3f-4a25-a79d-0b2bb3c4377e",
   "metadata": {},
   "source": [
    "Before we start this assignment, we must prepare the necessary dataset for this, so we will install necessary modules first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13ceed7d-066c-47b9-a191-24dee1a81821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import keras.layers as layers\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f962b106-f7a8-4f2f-8f06-143d1c4d238d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\datasets\\flower_photos_extracted/flower_photos\n"
     ]
    }
   ],
   "source": [
    "dataset_URL = \"http://download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "path_to_zip = keras.utils.get_file('flower_photos.tgz', origin=dataset_URL, extract=True, cache_dir='.')\n",
    "dataset_dir = os.path.join(os.path.dirname(path_to_zip), \"flower_photos_extracted/flower_photos\")\n",
    "print(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "860b3202-63c9-4ec2-9196-7a3a4c1ef309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total daisy images: 633\n",
      "total dandelion images: 898\n",
      "total roses images: 641\n",
      "total sunflowers images: 699\n",
      "total tulips images: 799\n"
     ]
    }
   ],
   "source": [
    "daisy_dir = os.path.join(dataset_dir, \"daisy\")\n",
    "dandelion_dir = os.path.join(dataset_dir, \"dandelion\")\n",
    "roses_dir = os.path.join(dataset_dir, \"roses\")\n",
    "sunflowers_dir = os.path.join(dataset_dir, \"sunflowers\")\n",
    "tulips_dir = os.path.join(dataset_dir, \"tulips\")\n",
    "\n",
    "print('total daisy images:', len(os.listdir(daisy_dir)))\n",
    "print('total dandelion images:', len(os.listdir(dandelion_dir)))\n",
    "print('total roses images:', len(os.listdir(roses_dir)))\n",
    "print('total sunflowers images:', len(os.listdir(sunflowers_dir)))\n",
    "print('total tulips images:', len(os.listdir(tulips_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080241ca-3adf-49ce-972a-36944c90457b",
   "metadata": {},
   "source": [
    "# Splitting into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01261bb4-1860-4e7b-90ab-af19005da448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2936 files for training.\n",
      "Found 3670 files belonging to 5 classes.\n",
      "Using 734 files for validation.\n"
     ]
    }
   ],
   "source": [
    "img_height, img_width = 128, 128\n",
    "batch_size = 32\n",
    "\n",
    "# resize all the images to the same size as expected by VGG model we downloaded above\n",
    "image_size = (img_height, img_width)\n",
    "\n",
    "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='int'\n",
    ")\n",
    "val_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='int'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7edd9fb-4e1c-4a30-8d92-d31c039e75b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images shape: (32, 128, 128, 3)\n",
      "labels shape: (32,)\n",
      "tf.Tensor([1 4 1 2 4 2 4 0 4 4 4 2 1 3 4 0 3 4 3 4 0 2 3 4 3 4 1 0 1 0 3 4], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    print('images shape:', images.shape)\n",
    "    print('labels shape:', labels.shape)\n",
    "    print(tf.squeeze(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54d066d0-534e-465c-aca3-3c1275458723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
      "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"
     ]
    }
   ],
   "source": [
    "## print out the class indices\n",
    "print(train_ds.class_names)\n",
    "print(val_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f4c323-6d9b-41c3-8b0e-6364edd3199d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b0528d-8e0d-4f95-82a6-0ac6db8851c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
